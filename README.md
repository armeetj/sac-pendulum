# sac-pendulum
Inverted double pendulum with Soft Actor Critic (SAC) RL model.

## v4
**Highest score**: 9359.85

After 614 episodes (< 5 min of training).

**Demo**:


https://github.com/user-attachments/assets/d70811ca-e7ba-4bd9-a8f8-0a89237f166b

**Score Plots**:
![v4_scores](https://github.com/user-attachments/assets/d0c9dff2-8b22-4266-938d-7ccb151ccd6a)


## v5

I trained the double inverted pendulum using InvertedDoublePendulum-v5 earlier. There was some confusion, and other group members used v4, but I wanted to include my v5 results anyways!

**Highest score**: 82,812

**Demo**: 

https://github.com/user-attachments/assets/0d966f26-0bce-41c8-bf3d-0004cd8b8349

**Score Plots**:
![v5_scores](https://github.com/user-attachments/assets/96e9b5b2-3b32-41ab-aa0c-27d748e505fc)


## Documentation
All documentation is automatically generated by `pdoc3`.  

To generate documentation, run `pdoc --html -o docs . -f`.  

Make sure you do NOT have `pdoc` and only use `pip install pdoc3` or there 
might be package conflicts.

## References
In the code, I sometimes reference back to the original paper + other resources.

> [1] [paper](https://arxiv.org/pdf/1801.01290)  
> [2] [lib](https://skrl.readthedocs.io/en/latest/) - provided by Sorina  
> [3] [article](https://medium.com/@sthanikamsanthosh1994/reinforcement-learning-part-5-soft-actor-critic-sac-network-using-tensorflow2-697917b4b752)  
> [4] [video](https://github.com/philtabor/Youtube-Code-Repository/blob/master/ReinforcementLearning/PolicyGradient/SAC/)
